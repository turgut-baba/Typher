/**
 * @file Onnx.hpp
 * @author Turgut BababalÄ±m (turgutbababalim@gmail.com)
 * @brief Onnxruntime for inferance. 
 * @version 0.1
 * @date 2024-10-09
 * 
 * @copyright Copyright (c) 2024
 * 
 */

#ifndef INFERENCE_ONNX_HPP
#define INFERENCE_ONNX_HPP

#include "Engine.hpp"
#include "Utils/string_ops.hpp"

#include <numeric>
#include <vector>
#include <onnxruntime_cxx_api.h>

namespace Typher
{
    class Onnx: public Engine<float>
    {
    public:
        explicit Onnx(std::string& instance_name);

        void Run() override;

        void fill(std::vector<float>& input) override;

        void load_model(std::string model_path) override;

        std::vector<float> get_output() override;

        void set_gpu(bool gpu_switch) override;

        virtual ~Onnx() = default;
    private:
        std::unique_ptr<Ort::Session> session;

        Ort::AllocatorWithDefaultOptions allocator;

        const char* inputName;
        std::vector<int64_t> inputDims;

        const char* outputName;
        std::vector<int64_t> outputDims;
    };
};

#endif